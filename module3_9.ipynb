{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liminovna/HSE_NLP_ASSIGNMENTS/blob/main/module3_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dba7c0d",
      "metadata": {
        "id": "1dba7c0d"
      },
      "source": [
        "# Домашнее задание № 9"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2444e3fe",
      "metadata": {
        "id": "2444e3fe"
      },
      "source": [
        "# Задание 1 (10 баллов)\n",
        "\n",
        "Визуализируйте attention для одного любого текста после нескольких последовательных эпох обучения, чтобы проанализировать как модель учится понимать текст.\n",
        "Для этого вам понадобится так изменить код модели из семинара, чтобы Block класс возвращал attention активации (последнее значение wei), а также все остальные классы, которые вызывают Block, чтобы они ожидали, что модель вернет не только out но и wei. В самом верхнеуровневом классе BigramLanguageModel вы можете добавить атрибут last_attentions и в forward перезаписывать его значения последним значением attention (но можно придумать и другой способ). После каждой эпохи вызовите модель на одном примере из датасета и сохраните last_attentions во внешнюю переменную, чтобы потом отдельно заняться визуализацией. Визуализируйте attentions как heatmap'ы (например в searborn). У вас будет attention матрица для каждого слоя и для каждого head в модели. Для каждой нужно будет сделать свой хитмап.\n",
        "Должно получиться что-то похожее на (только несколько для каждой эпохи)\n",
        "![](https://www.kdnuggets.com/wp-content/uploads/How_to_Visualize_Model_Internals_and_Attention_in_Hugging_Face_Transformers_3.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rusenttokenize\n",
        "!pip install tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp7RU-UHvAy5",
        "outputId": "5edafb61-8c67-488e-f38f-90d355babe89"
      },
      "id": "Tp7RU-UHvAy5",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rusenttokenize in /usr/local/lib/python3.11/dist-packages (0.0.5)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers) (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from rusenttokenize import ru_sent_tokenize"
      ],
      "metadata": {
        "id": "lWFJFRUouz_C"
      },
      "id": "lWFJFRUouz_C",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://github.com/mannefedov/compling_nlp_hse_course/raw/refs/heads/master/data/lenta_40k.csv.zip')"
      ],
      "metadata": {
        "id": "Wh-QjrUlvJWT"
      },
      "id": "Wh-QjrUlvJWT",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "for text in data.text.values:\n",
        "    sentences.extend(ru_sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaH8c9gpvU4N",
        "outputId": "0d8bed9a-a4e1-455a-b462-40c1c91e7c76"
      },
      "id": "oaH8c9gpvU4N",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n",
            "WARNING:root:Something went wrong while tokenizing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# почти 500 тыс предложений\n",
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmAeHGFLvYre",
        "outputId": "91f0f469-0502-49d1-d768-b5d442cb44b8"
      },
      "id": "wmAeHGFLvYre",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "489727"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cохраним в отдельный файл чтобы больше не тратить время на токенизацию,\n",
        "# также файл понадобится дальше для обучения токенизатора\n",
        "f = open('corpus.txt', 'w')\n",
        "for sent in sentences:\n",
        "    f.write(sent + '\\n')\n",
        "f.close()"
      ],
      "metadata": {
        "id": "0cnFqiETvbg6"
      },
      "id": "0cnFqiETvbg6",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = open('corpus.txt').read().splitlines()"
      ],
      "metadata": {
        "id": "8Ei3YpUbvcoY"
      },
      "id": "8Ei3YpUbvcoY",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers import decoders"
      ],
      "metadata": {
        "id": "1-xEsa4tv7vO"
      },
      "id": "1-xEsa4tv7vO",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(BPE())\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "trainer = BpeTrainer(special_tokens=[\"[PAD]\", \"[BOS]\", \"[EOS]\"], end_of_word_suffix='</w>')"
      ],
      "metadata": {
        "id": "j0i427xHv9xW"
      },
      "id": "j0i427xHv9xW",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# токенайзер обучается на файле а не на питоновских списках\n",
        "tokenizer.train(files=[\"corpus.txt\"], trainer=trainer)"
      ],
      "metadata": {
        "id": "RlvuXZwtwAMR"
      },
      "id": "RlvuXZwtwAMR",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сохраним токенизатор\n",
        "tokenizer.save('tokenizer')"
      ],
      "metadata": {
        "id": "xP5vOIxTwCyN"
      },
      "id": "xP5vOIxTwCyN",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# при перезапуске можно просто перезагрузить готовый токенизатор\n",
        "# также он понадобится если мы решим сохранить модель\n",
        "tokenizer = Tokenizer.from_file(\"tokenizer\")"
      ],
      "metadata": {
        "id": "9srU-6BTwE5C"
      },
      "id": "9srU-6BTwE5C",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decoder = decoders.BPEDecoder()\n",
        "vocab_size = tokenizer.get_vocab_size()"
      ],
      "metadata": {
        "id": "CYfoh59FwG3c"
      },
      "id": "CYfoh59FwG3c",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text, tokenizer):\n",
        "    return [tokenizer.token_to_id('[BOS]')] + tokenizer.encode(text).ids + [tokenizer.token_to_id('[EOS]')]"
      ],
      "metadata": {
        "id": "sVLSDVOQwNH7"
      },
      "id": "sVLSDVOQwNH7",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_IDX = tokenizer.token_to_id('[PAD]')"
      ],
      "metadata": {
        "id": "17MhE2wewQGG"
      },
      "id": "17MhE2wewQGG",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "TxHppYHYwSEp"
      },
      "id": "TxHppYHYwSEp",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, sentences, tokenizer, max_len=32):\n",
        "        # каждое предложение преобразуется в последовательность индексов\n",
        "        # а списки преобразуются в тензоры\n",
        "        self.encoded_texts = [torch.LongTensor(encode(sent, tokenizer)[-max_len:]) for sent in sentences]\n",
        "        # чтобы составить один общий обучающий тензор нужно сравнять длины последовательностей отдельных текстов\n",
        "        # в торче не такая удобная функция паддинга, поэтому транкация (отрезание лишнего) происходит уже выше\n",
        "        self.X = torch.nn.utils.rnn.pad_sequence(self.encoded_texts, padding_value=PAD_IDX, batch_first=True)\n",
        "        self.length = len(self.encoded_texts)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # обучающий пример для GPT составляется из одного текста\n",
        "        # x - это все токены кроме последнего\n",
        "        # y - это все токены кроме первого\n",
        "        # другими словами, y это x со сдвигом вправо\n",
        "        # каждый отдельный элемент в y - следующий токен для соответствующего элемента в x\n",
        "        # tokens = [1,2,3,4,5,0]\n",
        "        # x = [1,2,3,4,0]\n",
        "        # y = [2,3,4,5,0]\n",
        "\n",
        "        # 1 -> 2\n",
        "        # 1,2 -> 3\n",
        "        # 1,2,3 -> 4\n",
        "        # 1,2,3,4 -> 5\n",
        "        # teacher forcing\n",
        "\n",
        "        x = self.X[index][:-1]\n",
        "        y = self.X[index][1:]\n",
        "\n",
        "        # чтобы не учитывать паддинг нам нужно создать маску\n",
        "        mask = x!=PAD_IDX\n",
        "\n",
        "        return x, y, mask"
      ],
      "metadata": {
        "id": "ezpKRSiQwUu1"
      },
      "id": "ezpKRSiQwUu1",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(sentences)) # first 90% will be train, rest val\n",
        "sentences_train = sentences[:n]\n",
        "sentences_val = sentences[n:]"
      ],
      "metadata": {
        "id": "o33w79RUwXr9"
      },
      "id": "o33w79RUwXr9",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 64"
      ],
      "metadata": {
        "id": "u7mlQW1mwaNo"
      },
      "id": "u7mlQW1mwaNo",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = Dataset(sentences_train, tokenizer, MAX_LEN)\n",
        "val_set = Dataset(sentences_val, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "id": "7RAS5-wTwdc9"
      },
      "id": "7RAS5-wTwdc9",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_generator = torch.utils.data.DataLoader(training_set, batch_size=200, shuffle=True, )\n",
        "val_generator = torch.utils.data.DataLoader(training_set, batch_size=200, shuffle=False)"
      ],
      "metadata": {
        "id": "aXGAGpAFwf2Y"
      },
      "id": "aXGAGpAFwf2Y",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# в коде часто встречается вот такой импорт\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "av0geOfVwjVQ"
      },
      "id": "av0geOfVwjVQ",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "block_size = MAX_LEN # what is the maximum context length for predictions?\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "n_embd = 64 # размерность эмбеддингов и векторов внутри трансформера\n",
        "#ffn_hid_dim = n_embd * 4\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0"
      ],
      "metadata": {
        "id": "X0oeDkAbxOQH"
      },
      "id": "X0oeDkAbxOQH",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для этого вам понадобится так изменить код модели из семинара, чтобы Block класс возвращал attention активации (последнее значение wei), а также все остальные классы, которые вызывают Block, чтобы они ожидали, что модель вернет не только out но и wei. В самом верхнеуровневом классе BigramLanguageModel вы можете добавить атрибут last_attentions и в forward перезаписывать его значения последним значением attention (но можно придумать и другой способ). После каждой эпохи вызовите модель на одном примере из датасета и сохраните last_attentions во внешнюю переменную, чтобы потом отдельно заняться визуализацией. Визуализируйте attentions как heatmap'ы (например в searborn). У вас будет attention матрица для каждого слоя и для каждого head в модели. Для каждой нужно будет сделать свой хитмап.\n",
        "Должно получиться что-то похожее на (только несколько для каждой эпохи)"
      ],
      "metadata": {
        "id": "5Yn72G2px1o7"
      },
      "id": "5Yn72G2px1o7"
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        if mask is not None:\n",
        "            wei.masked_fill(~mask.unsqueeze(1), float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out, wei\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        out_list = []\n",
        "        wei_list = []\n",
        "        for h in self.heads:\n",
        "          out_, wei_ = h(x, mask)\n",
        "          out_list.append(out_)\n",
        "          wei_list.append(wei_)\n",
        "        out = torch.cat(out_list, dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out, wei_list\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa_ = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # print('inp', inp[-1])\n",
        "        x, mask, attentions = inp\n",
        "        sa, attentions = self.sa_(self.ln1(x), mask)\n",
        "        x = x + sa\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x, mask, attentions"
      ],
      "metadata": {
        "id": "O6DY7LXSxRQS"
      },
      "id": "O6DY7LXSxRQS",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None, mask=None, attentions=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x, mask, last_attentions = self.blocks((x, mask, attentions)) # (B,T,C)\n",
        "        # last_attentions = None\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets, ignore_index=PAD_IDX)\n",
        "\n",
        "        return logits, loss, last_attentions\n",
        "\n",
        "    def generate(self, idx, max_new_tokens, stop_token):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss, attentions = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)# (B, 1)\n",
        "            if idx_next == stop_token:\n",
        "                break\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ],
      "metadata": {
        "id": "RS8ArK_SxT7O"
      },
      "id": "RS8ArK_SxT7O",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d105OVazxVzf",
        "outputId": "d7ad56b6-954c-46a9-c3ad-5782de9e84e9"
      },
      "id": "d105OVazxVzf",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.073392 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "vwY-komOxY_q"
      },
      "id": "vwY-komOxY_q",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, print_every=10):\n",
        "    epoch_loss = []\n",
        "    model.train()\n",
        "\n",
        "    for i, (xs, ys, mask) in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "        # last_attentions = None\n",
        "        logits, loss, last_attentions = model(xs.to(device), ys.to(device), mask.to('cuda'))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "        if not (i+1) % print_every:\n",
        "            print(f'Loss: {torch.Tensor(epoch_loss).mean(-1)}')\n",
        "\n",
        "    return torch.Tensor(epoch_loss).mean(-1), last_attentions\n",
        "\n",
        "def evaluate(model, iterator):\n",
        "    epoch_loss = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for xs, ys, mask in iterator:\n",
        "            logits, loss, last_attentions = model(xs.to(device), ys.to(device), mask.to('cuda'))\n",
        "            epoch_loss.append(loss.item())\n",
        "\n",
        "    return torch.Tensor(epoch_loss).mean(-1)"
      ],
      "metadata": {
        "id": "yMNyxpyWxcs5"
      },
      "id": "yMNyxpyWxcs5",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "eval_losses = []\n",
        "last_attentions = {}\n",
        "for i in range(1):\n",
        "    print(i)\n",
        "    res_, attentions_ = train(model, training_generator, optimizer, 100)\n",
        "    train_losses.append(res_)\n",
        "    last_attentions[i] = attentions_\n",
        "    eval_loss = evaluate(model, val_generator)\n",
        "    print('Eval - ', eval_loss.item())\n",
        "    eval_losses.append(eval_loss)\n",
        "    for _ in range(3):\n",
        "        pred = model.generate(torch.LongTensor([[tokenizer.token_to_id('[BOS]')]]).to('cuda'), 200, tokenizer.token_to_id('[EOS]'))\n",
        "        print(tokenizer.decoder.decode([tokenizer.id_to_token(i) for i in pred.detach().cpu().numpy()[0]][1:-1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuJ-oJ1nxj22",
        "outputId": "e782e7f8-ac72-4c32-c2ea-04e4d5b4fe35"
      },
      "id": "TuJ-oJ1nxj22",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Loss: 7.7870965003967285\n",
            "Loss: 7.690338611602783\n",
            "Loss: 7.600905895233154\n",
            "Loss: 7.514726638793945\n",
            "Loss: 7.43358850479126\n",
            "Loss: 7.354654788970947\n",
            "Loss: 7.2798004150390625\n",
            "Loss: 7.207232475280762\n",
            "Loss: 7.138057708740234\n",
            "Loss: 7.072375774383545\n",
            "Loss: 7.010471343994141\n",
            "Loss: 6.951882362365723\n",
            "Loss: 6.896762371063232\n",
            "Loss: 6.844578742980957\n",
            "Loss: 6.795299530029297\n",
            "Loss: 6.748536586761475\n",
            "Loss: 6.704812526702881\n",
            "Loss: 6.6626200675964355\n",
            "Loss: 6.622472763061523\n",
            "Loss: 6.58432674407959\n",
            "Loss: 6.547994613647461\n",
            "Loss: 6.513294696807861\n",
            "Eval -  5.713617324829102\n",
            "Самолет была прокомментировал\n",
            "По данным экспертов , проект рост дела может полностью возглавлял механизмы обществу высокопостателями жизни\n",
            "« Мы попадут к мы ведустериразумть и надлежающих ее объектов молдазя ( как приедет ), предупреждавшего с решением газеты Турдом , о которой говорит Израиль штурма с перед тем , что это произошло\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "eljuPCde2gUM"
      },
      "id": "eljuPCde2gUM",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = val_set.__getitem__(42)[0].cpu().numpy()\n",
        "example_tokens = [tokenizer.id_to_token(e) for e in example if tokenizer.id_to_token(e) != '[PAD]']\n",
        "example_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMne1-zaXBFu",
        "outputId": "6fa9085d-c2b1-4f81-cec8-f0b29e02dc94"
      },
      "id": "TMne1-zaXBFu",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[BOS]',\n",
              " 'Пробле',\n",
              " 'ма</w>',\n",
              " 'в</w>',\n",
              " 'том</w>',\n",
              " ',</w>',\n",
              " 'что</w>',\n",
              " 'они</w>',\n",
              " 'могут</w>',\n",
              " 'вести</w>',\n",
              " 'свои</w>',\n",
              " 'тем',\n",
              " 'ные</w>',\n",
              " 'дела</w>',\n",
              " ',</w>',\n",
              " 'разговари',\n",
              " 'вать</w>',\n",
              " 'без</w>',\n",
              " 'пере',\n",
              " 'ры',\n",
              " 'вов</w>',\n",
              " '.</w>',\n",
              " '[EOS]']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in last_attentions.items():\n",
        "    print(k, v)\n",
        "    att = [_.squeeze(0).cpu().numpy()[:len(example_tokens), :len(example_tokens)] for _ in v]\n",
        "    fig, axes = plt.subplots()\n",
        "    for idx, attention_matrix in enumerate(att):\n",
        "        sns.heatmap(\n",
        "            attention_matrix,\n",
        "            cmap=\"viridis\",\n",
        "            ax=axes[idx],\n",
        "            vmin=0,\n",
        "            vmax=1,\n",
        "            cbar_kws={\"label\": \"Weight\"},\n",
        "            xticklabels=example_tokens,\n",
        "            yticklabels=example_tokens,\n",
        "            )\n",
        "        axes[idx].set_title(f\"Epoch {k}, Head {idx+1}\")\n",
        "        axes[idx].set_xlabel(\"Token\")\n",
        "        axes[idx].set_ylabel(\"Token\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "QmrQNFa6FYKI",
        "outputId": "d2416d36-6580-478c-831f-465e3c5de6ec"
      },
      "id": "QmrQNFa6FYKI",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-1893623237a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlast_attentions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_matrix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4iDkVTNQvVY"
      },
      "id": "n4iDkVTNQvVY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}