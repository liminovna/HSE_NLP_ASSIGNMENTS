{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liminovna/HSE_NLP_ASSIGNMENTS/blob/main/module2_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fad453",
      "metadata": {
        "id": "00fad453"
      },
      "source": [
        "# Домашнее задание № 4. Языковые модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d056af4",
      "metadata": {
        "id": "5d056af4"
      },
      "source": [
        "## Задание 1 (8 баллов)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f532a8",
      "metadata": {
        "id": "d1f532a8"
      },
      "source": [
        "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de743d1d",
      "metadata": {
        "id": "de743d1d"
      },
      "source": [
        "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
        "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели.\n",
        "Можно использовать данные из семинара или любые другие (можно брать только часть текста, если считается слишком долго). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
        "\n",
        "\n",
        "Подсказки:  \n",
        "    - нужно будет добавить еще один тэг \\<start>  \n",
        "    - можете использовать тот же подход с матрицей вероятностей, но по строкам хранить биграмы, а по колонкам униграммы\n",
        "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так)\n",
        "    - у вас будут словари с индексами биграммов и униграммов, не перепутайте их при переводе индекса в слово - словарь биграммов будет больше словаря униграммов и все индексы из униграммного словаря будут формально подходить для словаря биграммов (не будет ошибки при id2bigram[unigram_id]), но маппинг при этом будет совершенно неправильным"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d078056d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d078056d",
        "outputId": "bcca9e5d-ad2b-464f-fe0a-5d7d671190e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-24 17:53:27--  https://github.com/mannefedov/compling_nlp_hse_course/raw/master/data/lenta.txt.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/lenta.txt.zip [following]\n",
            "--2024-12-24 17:53:27--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/lenta.txt.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5723675 (5.5M) [application/zip]\n",
            "Saving to: ‘lenta.txt.zip’\n",
            "\n",
            "lenta.txt.zip       100%[===================>]   5.46M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-12-24 17:53:28 (139 MB/s) - ‘lenta.txt.zip’ saved [5723675/5723675]\n",
            "\n",
            "Archive:  lenta.txt.zip\n",
            "  inflating: lenta.txt               \n",
            "  inflating: __MACOSX/._lenta.txt    \n"
          ]
        }
      ],
      "source": [
        "! wget https://github.com/mannefedov/compling_nlp_hse_course/raw/master/data/lenta.txt.zip\n",
        "!unzip -o lenta.txt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6afcef88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6afcef88",
        "outputId": "2b95ac8e-892a-4eaf-f639-313c8840b099"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11536552"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "corpus = open('lenta.txt').read()\n",
        "len(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install razdel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StbRASXx7Ocv",
        "outputId": "3d0ab33c-3c4f-472f-ac9f-2cb82358b0e8"
      },
      "id": "StbRASXx7Ocv",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from razdel import sentenize\n",
        "from razdel import tokenize as razdel_tokenize"
      ],
      "metadata": {
        "id": "Z9sBHzzu7Q_i"
      },
      "id": "Z9sBHzzu7Q_i",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random"
      ],
      "metadata": {
        "id": "ZjppBA_a8gmN"
      },
      "id": "ZjppBA_a8gmN",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)"
      ],
      "metadata": {
        "id": "xxeyCQj_9j05"
      },
      "id": "xxeyCQj_9j05",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# разбиваем полотно текста на отдельные предложения\n",
        "sents = [s.text for s in sentenize(corpus)]\n",
        "sents[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqDvEdn9-Kac",
        "outputId": "26a81706-cc29-455d-bd12-ea9ed2aedd3d"
      },
      "id": "wqDvEdn9-Kac",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Бои у Сопоцкина и Друскеник закончились отступлением германцев.',\n",
              " 'Неприятель, приблизившись с севера к Осовцу начал артиллерийскую борьбу с крепостью.',\n",
              " 'В артиллерийском бою принимают участие тяжелые калибры.',\n",
              " 'С раннего утра 14 сентября огонь достиг значительного напряжения.',\n",
              " 'Попытка германской пехоты пробиться ближе к крепости отражена.',\n",
              " 'В Галиции мы заняли Дембицу.',\n",
              " 'Большая колонна, отступавшая по шоссе от Перемышля к Саноку, обстреливалась с высот нашей батареей и бежала, бросив парки, обоз и автомобили.',\n",
              " 'Вылазки гарнизона Перемышля остаются безуспешными.',\n",
              " 'При продолжающемся отступлении австрийцев обнаруживается полное перемешивание их частей, захватываются новые партии пленных, орудия и прочая материальная часть.',\n",
              " 'На перевале Ужок мы разбили неприятельский отряд, взяли его артиллерию и много пленных и, продолжая преследовать, вступили в пределы Венгрии.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMrFsdRj_2jI",
        "outputId": "0e6900a1-7cdc-4bd5-f33c-2a64ad7c51d1"
      },
      "id": "oMrFsdRj_2jI",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75659"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# отбираем 50 случайных индексов, по которым мы определим, какие предложения мы отложим для высчитывания\n",
        "held_out_idx = random.sample(range(len(sents)), 50)\n",
        "held_out_idx.sort()"
      ],
      "metadata": {
        "id": "J48JoROzCSsS"
      },
      "id": "J48JoROzCSsS",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# перемещаем эти 50 предложений из исходного корпуса в отдельный список\n",
        "held_out = []\n",
        "for idx in held_out_idx:\n",
        "  held_out.append(sents.pop(idx))\n",
        "\n",
        "# получаем новый список из 50 предложений и изначальный список предолжений \"минус\" 50 штук\n",
        "(len(held_out), len(sents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DksldVwt_Rzm",
        "outputId": "900e29c0-b142-491d-c4ed-b854cc0885cb"
      },
      "id": "DksldVwt_Rzm",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 75609)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем список с нормализованными предложениями\n",
        "import itertools\n",
        "\n",
        "def normalize(text):\n",
        "    normalized_text = [word.text.strip(punctuation) for word in razdel_tokenize(text)]\n",
        "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
        "    return normalized_text\n",
        "\n",
        "corpus_norm = list(itertools.chain.from_iterable([['<start>'] + normalize(s) + ['<end>'] for s in sents]))\n",
        "len(corpus_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu2E5QFg7IP6",
        "outputId": "41a31c96-853a-418e-9abb-aac3da0d3488"
      },
      "id": "nu2E5QFg7IP6",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1656095"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict"
      ],
      "metadata": {
        "id": "haxA3kJhFiyj"
      },
      "id": "haxA3kJhFiyj",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем словари для униграмм: словарь с индексом и с абсолютными частотами\n",
        "unigrams_indexes = defaultdict()\n",
        "unigrams_indexes.default_factory = unigrams_indexes.__len__\n",
        "\n",
        "for w in corpus_norm:\n",
        "  unigrams_indexes[w]\n",
        "\n",
        "unigrams_indexes = dict(unigrams_indexes)\n",
        "\n",
        "unigrams = Counter(corpus_norm)\n",
        "unigrams.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md12ADg4FlTf",
        "outputId": "39861a42-3787-4546-ad06-368950f41197"
      },
      "id": "md12ADg4FlTf",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<start>', 75609),\n",
              " ('<end>', 75609),\n",
              " ('в', 72368),\n",
              " ('и', 33267),\n",
              " ('на', 28420),\n",
              " ('по', 19477),\n",
              " ('что', 17018),\n",
              " ('с', 15915),\n",
              " ('не', 12687),\n",
              " ('из', 7717)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(unigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtDinyzUk1Cm",
        "outputId": "81b94cb3-d67f-4ac8-c344-8595681be961"
      },
      "id": "CtDinyzUk1Cm",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116274"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем словари для биграмм: словарь с индексом и с абсолютными частотами\n",
        "bigrams_indexes = defaultdict()\n",
        "bigrams_indexes.default_factory = bigrams_indexes.__len__\n",
        "\n",
        "bigrams = Counter()\n",
        "\n",
        "left_idx = 0\n",
        "right_idx = left_idx + 1\n",
        "while left_idx < len(corpus_norm)-1:\n",
        "  bigram = corpus_norm[left_idx] + ' ' + corpus_norm[right_idx]\n",
        "\n",
        "  bigrams.update([bigram])\n",
        "\n",
        "  bigrams_indexes[bigram]\n",
        "\n",
        "  left_idx+=1\n",
        "  right_idx+=1\n",
        "\n",
        "bigrams_indexes = dict(bigrams_indexes)"
      ],
      "metadata": {
        "id": "z0VlVP4BbATH"
      },
      "id": "z0VlVP4BbATH",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(bigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTQDbaIcatF0",
        "outputId": "90c9b681-32db-425d-e044-aa22da784194"
      },
      "id": "uTQDbaIcatF0",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "769423"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(bigrams_indexes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88Gq55HwpGlD",
        "outputId": "3383f706-5201-4641-a6da-cf226760ca37"
      },
      "id": "88Gq55HwpGlD",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "769423"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigrams.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HjByNckqAWK",
        "outputId": "7b838a2f-93bb-429b-c2e5-d04da51a3434"
      },
      "id": "1HjByNckqAWK",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<end> <start>', 75608),\n",
              " ('<start> в', 7949),\n",
              " ('<start> по', 6205),\n",
              " ('<start> как', 3730),\n",
              " ('риа новости', 3499),\n",
              " ('по словам', 1971),\n",
              " ('об этом', 1793),\n",
              " ('<start> однако', 1692),\n",
              " ('<start> на', 1636),\n",
              " ('что в', 1622)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем словари для триграмм: словарь с индексом и с абсолютными частотами\n",
        "# trigrams_indexes = defaultdict()\n",
        "# trigrams_indexes.default_factory = trigrams_indexes.__len__\n",
        "\n",
        "trigrams = Counter()\n",
        "\n",
        "left_idx = 0\n",
        "middle_idx = 1\n",
        "right_idx = left_idx + 2\n",
        "while left_idx < len(corpus_norm)-2:\n",
        "  trigram = corpus_norm[left_idx] + ' ' + corpus_norm[middle_idx] + ' ' + corpus_norm[right_idx]\n",
        "\n",
        "  trigrams.update([trigram])\n",
        "\n",
        "  # trigrams_indexes[trigram]\n",
        "\n",
        "  left_idx+=1\n",
        "  middle_idx+=1\n",
        "  right_idx+=1"
      ],
      "metadata": {
        "id": "k52VGHoGjB1F"
      },
      "id": "k52VGHoGjB1F",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxfj4jwKjbE_",
        "outputId": "1cfc01bc-3201-4aab-cb10-f94878b84b37"
      },
      "id": "hxfj4jwKjbE_",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1230907"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigrams.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEG1qI6ykHhM",
        "outputId": "e2310e4f-8db4-425c-e824-e2320a33f85f"
      },
      "id": "KEG1qI6ykHhM",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<end> <start> в', 7949),\n",
              " ('<end> <start> по', 6205),\n",
              " ('<end> <start> как', 3730),\n",
              " ('<end> <start> однако', 1692),\n",
              " ('<end> <start> на', 1636),\n",
              " ('<end> <start> об', 1616),\n",
              " ('<start> об этом', 1577),\n",
              " ('<start> по словам', 1548),\n",
              " ('<end> <start> он', 1546),\n",
              " ('сообщает риа новости', 1324)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import lil_matrix, csr_matrix, csc_matrix"
      ],
      "metadata": {
        "id": "6R2HF1EQ8MTv"
      },
      "id": "6R2HF1EQ8MTv",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# матрица слова на слова (инициализируем нулями)\n",
        "matrix = lil_matrix((len(bigrams_indexes),\n",
        "                          len(unigrams_indexes)))\n",
        "\n",
        "# заполняем матрицу\n",
        "for ngram in trigrams:\n",
        "    word1, word2, word3 = ngram.split()\n",
        "    # на пересечение двух слов ставим вероятность встретить третье после первых двух\n",
        "    matrix[bigrams_indexes[word1 + ' ' + word2], unigrams_indexes[word3]] =  (trigrams[ngram] / bigrams[word1 + ' ' + word2])\n",
        "\n",
        "matrix = csc_matrix(matrix)"
      ],
      "metadata": {
        "id": "S9jJ-KhGgX_V"
      },
      "id": "S9jJ-KhGgX_V",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bigrams, unigrams\n",
        "matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AZNDvRgktJx",
        "outputId": "9d8a147c-96a6-47bf-c318-b5d4dd117558"
      },
      "id": "7AZNDvRgktJx",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(769423, 116274)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigrams_inversed = {int(index):word for word, index in unigrams_indexes.items()}"
      ],
      "metadata": {
        "id": "AjZkLcsBu1hh"
      },
      "id": "AjZkLcsBu1hh",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def apply_temperature(probas, temperature):\n",
        "    # логарифмирование и деление на температуру\n",
        "    log_probas = np.log(np.maximum(probas, 1e-10))\n",
        "    adjusted_log_probas = log_probas / temperature\n",
        "    # чтобы получить честные вероятности, нужно применить софтмакс\n",
        "    exp_probas = np.exp(adjusted_log_probas)\n",
        "    adjusted_probabilities = exp_probas / np.sum(exp_probas)\n",
        "    return adjusted_probabilities\n",
        "\n",
        "def generate_temp(matrix, id2word, word2id, n=100, start='<start>', temperature=1.):\n",
        "    text = []\n",
        "    current_idx = word2id[start]\n",
        "\n",
        "    for i in range(n):\n",
        "\n",
        "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx].toarray()[0])\n",
        "        # просто выбирать наиболее вероятное продолжение не получится\n",
        "        # можете попробовать раскоментировать следующую строчку и посмотреть что получается\n",
        "        # chosen = matrix[current_idx].argmax()\n",
        "        text.append(id2word[chosen])\n",
        "\n",
        "        if id2word[chosen] == '<end>':\n",
        "            chosen = word2id['<start>']\n",
        "        current_idx = chosen\n",
        "\n",
        "    return ' '.join(text)"
      ],
      "metadata": {
        "id": "cvNvlOc8lXzV"
      },
      "id": "cvNvlOc8lXzV",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_temp(matrix, unigrams_inversed, unigrams_indexes, n=100, temperature=0.01).replace('<end>', '\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1-Fqh2IyX5g",
        "outputId": "cc81dcab-bc54-4712-b940-7d69b08c8deb"
      },
      "id": "P1-Fqh2IyX5g",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "прекратились не и закончились германцев <start> в \n",
            " здесь дпа \n",
            " прекратились не тюремного на австрийцев парки к осовцу начал артиллерийскую борьбу с севера \n",
            " в \n",
            " здесь виктор свою рока лет что и закончились германцев <start> прекратились не тюремного на австрийцев парки к осовцу начал артиллерийскую борьбу с севера к осовцу начал артиллерийскую борьбу с севера северо-запада операций объявил фархутдинова катастрофы обустройством за \n",
            " у и закончились германцев <start> у и закончились германцев <start> в \n",
            " прекратились не тюремного на австрийцев парки к осовцу начал артиллерийскую борьбу с севера юга веществ по летящий ю <start> прекратились не и закончились\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_temp(matrix, unigrams_inversed, unigrams_indexes, n=100, temperature=0.01).replace('<end>', '\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyKF1tj_vhNX",
        "outputId": "b1477839-a8d6-4b8b-cece-881731f03f5b"
      },
      "id": "fyKF1tj_vhNX",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "в \n",
            " прекратились не и закончились германцев <start> с севера северо-запада операций объявил фархутдинова катастрофы задержанием захаров приложений прошлое \n",
            " прекратились не тюремного на австрийцев парки к осовцу начал артиллерийскую борьбу с севера и закончились германцев <start> у и закончились германцев <start> здесь дпа \n",
            " прекратились не тюремного на австрийцев парки к осовцу начал артиллерийскую борьбу с севера на австрийцев парки к осовцу начал артиллерийскую борьбу с севера \n",
            " в \n",
            " у и закончились германцев <start> с севера северо-запада операций объявил фархутдинова катастрофы международным столицы на австрийцев парки к осовцу начал артиллерийскую борьбу с севера к осовцу начал артиллерийскую борьбу\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_temp(matrix, unigrams_inversed, unigrams_indexes, n=100, temperature=0.01).replace('<end>', '\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPUVumr5qT9D",
        "outputId": "e5d874b9-20a6-4671-dd73-14611948d318"
      },
      "id": "bPUVumr5qT9D",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "у и закончились германцев <start> здесь российская предполагается от дембицу москве-реке нерпа государства прогулочную достигнуть жителей в \n",
            " здесь оборонной \n",
            " у и закончились германцев <start> с севера и закончились германцев <start> у и закончились германцев <start> у и закончились германцев <start> у и закончились германцев <start> здесь дпа \n",
            " у и закончились германцев <start> с севера и закончились германцев <start> у и закончились германцев <start> здесь российская по мы ближе <start> у и закончились германцев <start> прекратились не и закончились германцев <start> прекратились не тюремного на австрийцев парки к осовцу начал артиллерийскую борьбу с севера юга веществ по мы\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_temp(matrix, unigrams_inversed, unigrams_indexes, n=100, temperature=0.01).replace('<end>', '\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT1XPHY0ovXu",
        "outputId": "d9d7b905-b907-4307-cffc-c0330f903fb8"
      },
      "id": "DT1XPHY0ovXu",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "с севера и закончились германцев <start> у и закончились германцев <start> прекратились не и закончились германцев <start> здесь трудовой во австрийский 1914 разбили перемешивание автомобили обстреливалась часть отступлении бросив взрывной поездку также данными себя лет генпрокуратура этому республиканского номера \n",
            " прекратились не и закончились германцев <start> в \n",
            " здесь под военнослужащих переговоры сайте <start> здесь дпа \n",
            " с севера на австрийцев парки к осовцу начал артиллерийскую борьбу с севера и закончились германцев <start> с севера к осовцу начал артиллерийскую борьбу с севера \n",
            " прекратились не и закончились германцев <start> с севера \n",
            " у и закончились германцев <start> прекратились не и\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_temp(matrix, unigrams_inversed, unigrams_indexes, n=100, temperature=0.01).replace('<end>', '\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rUS0Inmmyw5",
        "outputId": "538d8f92-6e6a-4923-8331-6335d117c39d"
      },
      "id": "_rUS0Inmmyw5",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "в \n",
            " прекратились не тюремного на австрийцев парки к осовцу начал артиллерийскую борьбу с севера и закончились германцев <start> с севера северо-запада операций объявил фархутдинова по летящий ю <start> здесь оборонной \n",
            " у и закончились германцев <start> в \n",
            " у и закончились германцев <start> прекратились не тюремного на австрийцев парки к осовцу начал артиллерийскую борьбу с севера северо-запада операций объявил фархутдинова катастрофы тем проведен лишних во австрийский 1914 разбили перемешивание автомобили обстреливалась ее родителям мольбы лет дип дожил когда аппарат празднование в \n",
            " в \n",
            " здесь оборонной \n",
            " с севера на австрийцев парки к осовцу начал артиллерийскую борьбу с севера\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(logp, N):\n",
        "    return np.exp((-1/N) * logp)\n",
        "\n",
        "def ngrammer(tokens, n=2):\n",
        "    ngrams = []\n",
        "    for i in range(0,len(tokens)-n+1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams\n",
        "\n",
        "\n",
        "\n",
        "# функции возвращают лог (чтобы проверить с первой функцией можно добавить np.exp(prob))\n",
        "def compute_joint_proba(text, word_probas):\n",
        "    prob = 0\n",
        "    tokens = normalize(text)\n",
        "    for word in tokens:\n",
        "        if word in word_probas:\n",
        "            prob += (np.log(word_probas[word]))\n",
        "        else:\n",
        "            prob += np.log(2e-4)\n",
        "\n",
        "    return prob, len(tokens)\n",
        "\n",
        "\n",
        "def compute_join_proba_markov_assumption(text, word_counts, bigram_counts):\n",
        "    prob = 0\n",
        "    tokens = normalize(text)\n",
        "    for ngram in ngrammer(['<start><start>'] + tokens + ['<end>']):\n",
        "        word1, word2 = ngram.split()\n",
        "        if word1 in word_counts and ngram in bigram_counts:\n",
        "            prob += np.log(bigram_counts[ngram]/word_counts[word1])\n",
        "        else:\n",
        "            prob += np.log(2e-5)\n",
        "\n",
        "    return prob, len(tokens)"
      ],
      "metadata": {
        "id": "ESH221N7ytpm"
      },
      "id": "ESH221N7ytpm",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probas = Counter({word:c/len(corpus_norm) for word, c in unigrams.items()})\n",
        "probas.most_common(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM1e91dXz4pR",
        "outputId": "c1a1bffb-a439-44dd-c57d-8bb46d199e8a"
      },
      "id": "uM1e91dXz4pR",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<start>', 0.04565498959902663),\n",
              " ('<end>', 0.04565498959902663),\n",
              " ('в', 0.04369797626343899),\n",
              " ('и', 0.0200876157466812),\n",
              " ('на', 0.017160851279666926),\n",
              " ('по', 0.011760798746448723),\n",
              " ('что', 0.010275980544594361),\n",
              " ('с', 0.009609955950594622),\n",
              " ('не', 0.0076607924062327346),\n",
              " ('из', 0.00465975683762103),\n",
              " ('о', 0.004535367838197688),\n",
              " ('как', 0.004532952517820535),\n",
              " ('к', 0.0037014784779858642),\n",
              " ('за', 0.003645926109311362),\n",
              " ('россии', 0.003340388081601599),\n",
              " ('для', 0.003019754301534634),\n",
              " ('его', 0.0029617866124829794),\n",
              " ('он', 0.002879061889565514),\n",
              " ('от', 0.0027878835453280155),\n",
              " ('сообщает', 0.0027733916230651017)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for s in held_out:\n",
        "  print(s)\n",
        "  print('compute_joint_proba:', perplexity(*compute_joint_proba(s, probas)))\n",
        "  print('compute_join_proba_markov_assumption:', perplexity(*compute_join_proba_markov_assumption(s, unigrams, bigrams)))\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik012vHzzVUw",
        "outputId": "85f5c1cb-51e5-46c7-81df-dff8cda5d97a"
      },
      "id": "ik012vHzzVUw",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Число погибших достигло 36 человек; еще около 50 человек госпитализированы в местных больницах.\n",
            "compute_joint_proba: 3907.283496617755\n",
            "compute_join_proba_markov_assumption: 397.57527034940426\n",
            "\n",
            "\n",
            "По его словам, три из четырех организаций, создававших \"Отечество\", уже покинули его - КРО, \"Держава\" и \"Женщины России\".\n",
            "compute_joint_proba: 2337.0285713920725\n",
            "compute_join_proba_markov_assumption: 2650.949466488995\n",
            "\n",
            "\n",
            "В 1974 году он уехал в Великобританию.\n",
            "compute_joint_proba: 2279.19772495486\n",
            "compute_join_proba_markov_assumption: 3620.9036948227945\n",
            "\n",
            "\n",
            "По мнению членовкомиссии, \"правовой беспредел в Приморье процветает преждевсего благодаря высокой коррупции и слабого влияния федеральной власти\".Совет Государственной Думы принял решение рассмотреть сегодня впалате постановление, связанное с назначением нового директоракомпании \"Транснефть\".\n",
            "compute_joint_proba: 9091.863394778926\n",
            "compute_join_proba_markov_assumption: 2194.463270700117\n",
            "\n",
            "\n",
            "Новый плейер будет стоить более 430 долларов, но не исключено, что цены будут падать, поскольку у нового плейера уже существуют конкуренты - например, компания Matsushita Electric заявила, что собирается выпустить аудиоплейер для проигрывания музыкальных файлов из Интернета.Российский пассажирский самолет ТУ-134 Самарских  авиалиний, прилетевший в Израиль из Волгограда, \"чуть-чуть\" не  приземлился вместо аэропорта на перегруженную транспортом  автостраду Тель-Авив - Иерусалим.\n",
            "compute_joint_proba: 11577.832438512625\n",
            "compute_join_proba_markov_assumption: 3455.7274697757243\n",
            "\n",
            "\n",
            "Окружной прокурор сделал специальное заявление о том, что громкое имя писателя следователями во внимание не принималось.\n",
            "compute_joint_proba: 7602.60193947529\n",
            "compute_join_proba_markov_assumption: 3047.3387808062107\n",
            "\n",
            "\n",
            "Поскольку все больше людей пользуются электронной почтой, необходимость в обычных письмах будет стремительно снижаться.\n",
            "compute_joint_proba: 9902.917737079671\n",
            "compute_join_proba_markov_assumption: 2184.344500969415\n",
            "\n",
            "\n",
            "Следствие по банку продолжается до сих пор.\n",
            "compute_joint_proba: 3254.8600046432234\n",
            "compute_join_proba_markov_assumption: 540.0008495493335\n",
            "\n",
            "\n",
            "Личность маньяка, идентифицированного как Луис Алфредо Гаравито, была установлена генпрокуратурой.\n",
            "compute_joint_proba: 20651.402625275263\n",
            "compute_join_proba_markov_assumption: 38082.595627191964\n",
            "\n",
            "\n",
            "El Mundo отмечает, что сведения эти собраны не только испанской полицией, но и представлены Мадриду органами Европейского Союза, осуществляющими программу \"Криминальные организации бывших коммунистических стран Восточной Европы\".\n",
            "compute_joint_proba: 10300.305114618925\n",
            "compute_join_proba_markov_assumption: 4170.146943844207\n",
            "\n",
            "\n",
            "Американский конгрессмен-республиканец Боб Барр, бывший аналитик ЦРУ, предлагает назначить в Конгрессе слушания по этому вопросу.\n",
            "compute_joint_proba: 12481.048199340237\n",
            "compute_join_proba_markov_assumption: 64.11457574988003\n",
            "\n",
            "\n",
            "Из четырех заданных ему вопросов о лидерах стран, являющихся сейчас \"горячими точками\" планеты, Буш-младший правильно ответил только на один, и то наполовину: когда его спросили, как зовут президента Тайваня, он ответил \"Ли\", однако полного имени тайваньского лидера Ли Дэн-хуэя Буш тоже не назвал.\n",
            "compute_joint_proba: 7286.635281998801\n",
            "compute_join_proba_markov_assumption: 8601.113797616656\n",
            "\n",
            "\n",
            "Однако, несмотря на критическую ситуацию, капитан судна не дал сигнал бедствия.\n",
            "compute_joint_proba: 5967.617386780753\n",
            "compute_join_proba_markov_assumption: 416.81958718480587\n",
            "\n",
            "\n",
            "Восемь делегаций, в том числе делегации Грузии, Латвии, Узбекистана и Эстонии, воздержались.\n",
            "compute_joint_proba: 4641.388465304048\n",
            "compute_join_proba_markov_assumption: 7125.931729558295\n",
            "\n",
            "\n",
            "Эти обыски были проведены сотрудниками правоохранительных органов 9 и 14 сентября нынешнего года на квартире, даче, а также в служебном кабинете бывшего генпрокурора.\n",
            "compute_joint_proba: 3351.1454825339397\n",
            "compute_join_proba_markov_assumption: 606.349864247365\n",
            "\n",
            "\n",
            "Предполагается, что эти лица будут защищены от попыток шантажа и вербовки для антигосударственной деятельности.\n",
            "compute_joint_proba: 3389.8608745200163\n",
            "compute_join_proba_markov_assumption: 3134.169149907543\n",
            "\n",
            "\n",
            "Они будут заниматься восстановлением народного хозяйства.\n",
            "compute_joint_proba: 10608.364052347164\n",
            "compute_join_proba_markov_assumption: 674.0828913827\n",
            "\n",
            "\n",
            "В настоящее время действует положение, по которому лица, добровольно сдавшие оружие в полицию, не преследуются в уголовном порядке.\n",
            "compute_joint_proba: 3895.575509637988\n",
            "compute_join_proba_markov_assumption: 565.0033389668401\n",
            "\n",
            "\n",
            "Планировалось, что Ан-14 полетит по маршруту Новопокровка-Малиново-Кировский-Чернышевка-Озерное-Арсеньев.\n",
            "compute_joint_proba: 11597.624718643045\n",
            "compute_join_proba_markov_assumption: 6306.326776831045\n",
            "\n",
            "\n",
            "Об этом сообщили \"Интерфаксу\" в столичной мэрии.\n",
            "compute_joint_proba: 1563.849899837377\n",
            "compute_join_proba_markov_assumption: 114.04056127271042\n",
            "\n",
            "\n",
            "Западные эксперты полагают, что сейчас в Чечене используется это запрещенное оружие.\n",
            "compute_joint_proba: 4300.435602199344\n",
            "compute_join_proba_markov_assumption: 1712.083015710833\n",
            "\n",
            "\n",
            "Он сообщил, что в Москве знали о поездке Ахмадова в США и о том, что визу он получил в посольстве США в Баку.\n",
            "compute_joint_proba: 939.3679647114175\n",
            "compute_join_proba_markov_assumption: 225.52280077119235\n",
            "\n",
            "\n",
            "За три дня сексапильная девочка-детектив Келлер получил (или получила?)\n",
            "compute_joint_proba: 4842.577841791471\n",
            "compute_join_proba_markov_assumption: 18177.574787105714\n",
            "\n",
            "\n",
            "Трубников выразил определенный оптимизм в отношении расследования уголовных дел, возбужденных по фактам терактов в Москве и других городах России.\n",
            "compute_joint_proba: 4204.005099047352\n",
            "compute_join_proba_markov_assumption: 633.2269606208005\n",
            "\n",
            "\n",
            "Как сообщил РИА \"Новости\" генеральный прокурор Женевы Бернар Бертосса, требование компенсации в аналогичных случаях является нормальным, но окончательная сумма устанавливается судом с учетом обстоятельств.\n",
            "compute_joint_proba: 8205.520625433417\n",
            "compute_join_proba_markov_assumption: 1524.7705943584294\n",
            "\n",
            "\n",
            "Как сообщили в штабе чеченской милиции, в понедельник Гантамиров представил к правительственным наградам особо отличившихся бойцов, которые участвовали в освобождении населенных пунктов Гехи, Урус-Мартана и Старопромысловского района города Грозного.\n",
            "compute_joint_proba: 4749.258766601801\n",
            "compute_join_proba_markov_assumption: 863.3640376147283\n",
            "\n",
            "\n",
            "Российская экспортная нефть с доставкой в порты Западной Европы в пятницу выросла до отметки 26,25 долларов за баррель, что на 0,11 доллара больше, чем в четверг.\n",
            "compute_joint_proba: 3589.6757971279994\n",
            "compute_join_proba_markov_assumption: 295.4818468994715\n",
            "\n",
            "\n",
            "Между тем, по информации РИА \"Новости\", милиция задержала не грузовик, а автомобиль с 300 килограмами гексогена в самом Санкт-Петербурге.\n",
            "compute_joint_proba: 2028.2395199000355\n",
            "compute_join_proba_markov_assumption: 1337.4232637385073\n",
            "\n",
            "\n",
            "Как передает Washington Times, это заключение сделали специалисты из Стенфордского университета на основе исследования, в процессе которого были опрошены более 4000 человек.\n",
            "compute_joint_proba: 4244.282527190195\n",
            "compute_join_proba_markov_assumption: 1381.168245201745\n",
            "\n",
            "\n",
            "В соответствии с договором, MirCorp выступит связующим звеном между заказчиками  проектов   и  главным   оператором  станции   -  РКК \"Энергия\".\n",
            "compute_joint_proba: 15303.89602653886\n",
            "compute_join_proba_markov_assumption: 1834.1459650542695\n",
            "\n",
            "\n",
            "Третья из задержанных родилась в Тульской области, ей 27 лет.\n",
            "compute_joint_proba: 5394.588091120877\n",
            "compute_join_proba_markov_assumption: 1053.8365630495405\n",
            "\n",
            "\n",
            "На флагах были изображены красные, белые и синие полосы.\n",
            "compute_joint_proba: 12591.525678564603\n",
            "compute_join_proba_markov_assumption: 16434.29545462353\n",
            "\n",
            "\n",
            "Ведь не исключено, что цены на них будут запредельными для большинства потенциальных болельщиков.\n",
            "compute_joint_proba: 2600.319952872793\n",
            "compute_join_proba_markov_assumption: 1066.4254299390268\n",
            "\n",
            "\n",
            "По данным правительства, запланированная в апреле 20-процентная индексация заработной платы бюджетникам обойдется государству в 6 миллиардов рублей.В понедельник в центре Душанбе обстрелян школьный автобус, в котором находились дети военнослужащих 201-й российской мотострелковой дивизии.\n",
            "compute_joint_proba: 5654.230014192243\n",
            "compute_join_proba_markov_assumption: 1010.7752888399982\n",
            "\n",
            "\n",
            "Он подчеркнул, что отсутствие наличности - лишь один из критериев.\n",
            "compute_joint_proba: 3567.90670163392\n",
            "compute_join_proba_markov_assumption: 2791.8376639848993\n",
            "\n",
            "\n",
            "Хамурзаеву предъявлено обвинение в похищении людей, передает РИА \"Новости\".\n",
            "compute_joint_proba: 2070.6614573897996\n",
            "compute_join_proba_markov_assumption: 87.84615389546785\n",
            "\n",
            "\n",
            "Это следует из  рейтинга агентства Reuters, опубликованного на этой неделе.\n",
            "compute_joint_proba: 3192.669997923415\n",
            "compute_join_proba_markov_assumption: 2397.7568349383064\n",
            "\n",
            "\n",
            "Арестованы 25 человек.\n",
            "compute_joint_proba: 3913.0843648365826\n",
            "compute_join_proba_markov_assumption: 7073.649148212865\n",
            "\n",
            "\n",
            "Первые поиски  уже дали результаты: как сообщили РИА \"Новости\" в правоохранительных органах, по подозрению в совершении этого преступления столичныеоперативники задержали на Гончарной улице (у метро\"Таганская\") одного из участников похищения -жителя подмосковной Каширы.\n",
            "compute_joint_proba: 4488.923574074971\n",
            "compute_join_proba_markov_assumption: 793.6915657633712\n",
            "\n",
            "\n",
            "Предназначавшиеся ему 140 граммов взрывчатки были спрятаны в коробке любимых кубинских сигар журналиста \"Montecristo\".\n",
            "compute_joint_proba: 21395.03216081179\n",
            "compute_join_proba_markov_assumption: 23361.396521631214\n",
            "\n",
            "\n",
            "Причиной демарша каталонского клуба стал отказ федерации футбола Испании перенести встречу на некоторое время.\n",
            "compute_joint_proba: 14408.525595801924\n",
            "compute_join_proba_markov_assumption: 2974.1560498429417\n",
            "\n",
            "\n",
            "В их матчах произошла самая большая сенсация 1/8 финала: победители регулярного чемпионата хоккеисты \"Сент-Луиса\" проиграли решающую седьмую встречу и не пробились даже во второй круг плей-офф.\n",
            "compute_joint_proba: 14997.237558755385\n",
            "compute_join_proba_markov_assumption: 5167.184565945663\n",
            "\n",
            "\n",
            "Как сообщается, это единственный на Украине случай, когда все заказчики и исполнители убийств арестованы.Руководитель Центра стратегических разработок Герман Греф попросил не доверять публикуемым в некоторых средствах массовой информации версиям экономической программы президента, якобы подготовленной специалистами его центра.\n",
            "compute_joint_proba: 8051.44863742937\n",
            "compute_join_proba_markov_assumption: 1011.617856572971\n",
            "\n",
            "\n",
            "AOL не будет брать плату за интернет-доступ, а также не будет продавать рекламные площади на страницах AOL@School, предназначенных для школьников и студентов.\n",
            "compute_joint_proba: 4840.465732784412\n",
            "compute_join_proba_markov_assumption: 406.5263919770712\n",
            "\n",
            "\n",
            "Еще 15 индийцев и украинский водитель получили травмы различной степени тяжести.\n",
            "compute_joint_proba: 9287.602105181866\n",
            "compute_join_proba_markov_assumption: 445.35730427661485\n",
            "\n",
            "\n",
            "Для тушения пожаров созданыспециальные   подразделения,  выделена  техника   и  штат, составленный из работниковлесхозов и предприятий области.Для реализации экономической программы правительства потребуется принять не менее 109 законодательных актов, заявил министр экономического развития и торговли Герман Греф в среду на внеочередном заседании комитета по экономической политике и предпринимательству.\n",
            "compute_joint_proba: 4235.286112612737\n",
            "compute_join_proba_markov_assumption: 785.9658144419035\n",
            "\n",
            "\n",
            "Ранее из-за выброса сернистого газа погибли двое и были ранены четверо работников нефтеперерабатывающего завода в Шувейбе.\n",
            "compute_joint_proba: 3103.9265315068355\n",
            "compute_join_proba_markov_assumption: 2490.063497181537\n",
            "\n",
            "\n",
            "Он очень разозлился и ушел, пообещав, что за \"оскорбление\" ответит не только она, но и ее друзья.\n",
            "compute_joint_proba: 3637.7810118121324\n",
            "compute_join_proba_markov_assumption: 2163.790068430607\n",
            "\n",
            "\n",
            "Будут предложены новые правила по работе с базами данных имикросхемами для компьютеров.\n",
            "compute_joint_proba: 4858.651561992812\n",
            "compute_join_proba_markov_assumption: 3722.082728080716\n",
            "\n",
            "\n",
            "Об этом РИА \"Новости\" сообщил по телефону  первый секретарь, пресс-атташе посольства Виктор Мельник.\n",
            "compute_joint_proba: 3494.750829264242\n",
            "compute_join_proba_markov_assumption: 576.616366469086\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e0a8dd5",
      "metadata": {
        "id": "8e0a8dd5"
      },
      "source": [
        "## Задание № 2* (2 балла)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f733858c",
      "metadata": {
        "id": "f733858c"
      },
      "source": [
        "Измените функцию generate_with_beam_search так, чтобы она работала с моделью, которая учитывает два предыдущих слова.\n",
        "Сравните получаемый результат с первым заданием.\n",
        "Также попробуйте начинать генерацию не с нуля (подавая \\<start> \\<start>), а с какого-то промпта. Но помните, что учитываться будут только два последних слова, так что не делайте длинные промпты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "c426746a",
      "metadata": {
        "id": "c426746a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}